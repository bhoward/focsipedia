

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Context-Free Grammars &#8212; FoCSipedia</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/mystnb.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Backus-Naur Form" href="bnf.html" />
    <link rel="prev" title="Finite-State Automata and Regular Languages" href="fsareg.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/SmartFoxLogo.jpeg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">FoCSipedia</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../attribution.html">
   Attribution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topics.html">
   Topics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../overview.html">
   Overview of Topics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../logic/index.html">
   Logic
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../sets/index.html">
   Sets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fp/index.html">
   Functional Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ds/index.html">
   Data Structures
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="reference internal" href="index.html">
   Formal Languages
  </a>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="languages.html">
     Languages
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="regexp.html">
     Regular Expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="regexpapp.html">
     Applications of Regular Expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="fsa.html">
     Finite-State Automata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="nfa.html">
     Nondeterministic Finite-State Automata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="fsareg.html">
     Finite-State Automata and Regular Languages
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Context-Free Grammars
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bnf.html">
     Backus-Naur Form
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="parsing.html">
     Parsing and Parse Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="pda.html">
     Pushdown Automata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="tm.html">
     General Grammars and Turing Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="computability.html">
     Computability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="halting.html">
     The Halting Problem
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/lang/cfg.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> On this page
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   Exercises
  </a>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="context-free-grammars">
<h1>Context-Free Grammars<a class="headerlink" href="#context-free-grammars" title="Permalink to this headline">¶</a></h1>
<p>(Content adapted from Critchlow &amp; Eck)</p>
<p>Both natural languages, such as English, and the
artificial languages used for programming have a structure
known as grammar or syntax. In order to form legal sentences
or programs, the parts of the language must be fit together
according to certain rules. For natural languages, the
rules are somewhat informal (although high-school English
teachers might have us believe differently). For programming
languages, the rules are absolute, and programs that violate
the rules will be rejected by a compiler.</p>
<p>In this chapter, we will study formal grammars and languages
defined by them. The languages we look at will, for the most part,
be “toy” languages, compared to natural languages or even
to programming languages, but the ideas and techniques are basic
to any study of language. In fact, many of the ideas arose
almost simultaneously in the 1950s in the work of linguists who were
studying natural language and programmers who were looking for
ways to specify the syntax of programming languages.</p>
<p>The grammars in this chapter are <strong>generative grammars</strong>.
A generative grammar is a set of rules that can be used to generate
all the legal strings in a language. We will also consider the closely
related idea of <strong>parsing</strong>. To parse a string means to determine
how that string can be generated according to the rules.</p>
<p>This chapter is a continuation of the preceding chapter.
Like a regular expression, a grammar is a way to specify a possibly
infinite language with a finite amount of information. In fact,
we will see that every regular language can be specified
by a certain simple type of grammar. We will also see that some languages
that can be specified by grammars are not regular.</p>
<p>In its most general form, a grammar is a set of <strong>rewriting
rules</strong>. A rewriting rule specifies that a certain string of symbols can
be substituted for all or part of another string. If <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(u\)</span> are
strings, then <span class="math notranslate nohighlight">\(w\longrightarrow u\)</span> is a rewriting rule that specifies that
the string <span class="math notranslate nohighlight">\(w\)</span> can be replaced by the string <span class="math notranslate nohighlight">\(u\)</span>. The symbol “<span class="math notranslate nohighlight">\(\longrightarrow\)</span>”
is read “can be rewritten as.” Rewriting rules are also called
<strong>production rules</strong> or <strong>productions</strong>, and
“<span class="math notranslate nohighlight">\(\longrightarrow\)</span>” can also be read as “produces.” For example,
if we consider strings over the alphabet <span class="math notranslate nohighlight">\(\{a,b,c\}\)</span>, then
the production rule <span class="math notranslate nohighlight">\(aba\longrightarrow cc\)</span> can be applied to the
string <span class="math notranslate nohighlight">\(abbabac\)</span> to give the string <span class="math notranslate nohighlight">\(abbccc\)</span>. The substring <span class="math notranslate nohighlight">\(aba\)</span>
in the string <span class="math notranslate nohighlight">\(abbabac\)</span> has been replaced with <span class="math notranslate nohighlight">\(cc\)</span>.</p>
<p>In a <strong>context-free grammar</strong>, every rewriting rule has the
form <span class="math notranslate nohighlight">\(A\longrightarrow w\)</span>, where <span class="math notranslate nohighlight">\(A\)</span> is single symbol and <span class="math notranslate nohighlight">\(w\)</span> is a string
of zero or more symbols. (The grammar is “context-free” in the
sense that <span class="math notranslate nohighlight">\(w\)</span> can be substituted for <span class="math notranslate nohighlight">\(A\)</span> wherever <span class="math notranslate nohighlight">\(A\)</span> occurs in a string,
regardless of the surrounding context in which <span class="math notranslate nohighlight">\(A\)</span> occurs.)
The symbols that occur on the left-hand
sides of production rules in a context-free grammar
are called <strong>non-terminal symbols</strong>.
By convention, the non-terminal symbols are usually uppercase letters.
The strings on the right-hand sides of the production rules can
include non-terminal symbols as well as other symbols, which are
called <strong>terminal symbols</strong>. By convention, the
terminal symbols are usually lowercase letters. Here are some
typical production rules that might occur in context-free grammars:
<span class="math notranslate nohighlight">\($ \begin{aligned}
   &amp;A\longrightarrow aAbB\\
   &amp;S\longrightarrow SS\\
   &amp;C\longrightarrow Acc\\
   &amp;B\longrightarrow b\\
   &amp;A\longrightarrow\varepsilon
   \end{aligned}
$\)</span>
In the last rule in this list, <span class="math notranslate nohighlight">\(\varepsilon\)</span> represents the empty string,
as usual. For example, this rule could be applied to the string
<span class="math notranslate nohighlight">\(aBaAcA\)</span> to produce the string <span class="math notranslate nohighlight">\(aBacA\)</span>. The first occurrence of
the symbol <span class="math notranslate nohighlight">\(A\)</span> in <span class="math notranslate nohighlight">\(aBaAcA\)</span> has been replaced by the empty string—which
is just another way of saying that the symbol has been dropped from the string.</p>
<p>In every context-free grammar, one of the non-terminal symbols is
designated as the <strong>start symbol</strong> of the grammar. The start symbol
is often, though not always, denoted by <span class="math notranslate nohighlight">\(S\)</span>. When the grammar
is used to generate strings in a language, the idea is to start
with a string consisting of nothing but the start symbol. Then
a sequence of production rules is applied. Each application of
a production rule to the string transforms the string to a new
string. If and when this process produces a string that consists
purely of terminal symbols, the process ends. That string of
terminal symbols is one of the strings in the language generated
by the grammar. In fact, the language consists precisely of
all strings of terminal symbols that can be produced in this way.</p>
<p>As a simple example, consider a grammar that has three production
rules: <span class="math notranslate nohighlight">\(S\longrightarrow aS\)</span>, <span class="math notranslate nohighlight">\(S\longrightarrow bS\)</span>, and <span class="math notranslate nohighlight">\(S\longrightarrow b\)</span>.
In this example, <span class="math notranslate nohighlight">\(S\)</span> is the only non-terminal symbol, and
the terminal symbols are <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span>. Starting from the
string <span class="math notranslate nohighlight">\(S\)</span>, we can apply any of the three rules of the grammar
to produce either <span class="math notranslate nohighlight">\(aS\)</span>, <span class="math notranslate nohighlight">\(bS\)</span>, or <span class="math notranslate nohighlight">\(b\)</span>. Since the string <span class="math notranslate nohighlight">\(b\)</span> contains
no non-terminals, we see that <span class="math notranslate nohighlight">\(b\)</span> is one of the strings in the language
generated by this grammar. The strings <span class="math notranslate nohighlight">\(aS\)</span> and <span class="math notranslate nohighlight">\(bS\)</span> are not in
that language, since they contain the non-terminal symbol <span class="math notranslate nohighlight">\(S\)</span>,
but we can continue to apply production rules to these strings.
From <span class="math notranslate nohighlight">\(aS\)</span>, for example, we can obtain <span class="math notranslate nohighlight">\(aaS\)</span>, <span class="math notranslate nohighlight">\(abS\)</span>, or <span class="math notranslate nohighlight">\(ab\)</span>.
From <span class="math notranslate nohighlight">\(abS\)</span>, we go on to obtain <span class="math notranslate nohighlight">\(abaS\)</span>, <span class="math notranslate nohighlight">\(abbS\)</span>, or <span class="math notranslate nohighlight">\(abb\)</span>.
The strings <span class="math notranslate nohighlight">\(ab\)</span> and <span class="math notranslate nohighlight">\(abb\)</span> are in the language generated by
the grammar. It’s not hard to see that any string of <span class="math notranslate nohighlight">\(a\)</span>’s and
<span class="math notranslate nohighlight">\(b\)</span>’s that ends with a <span class="math notranslate nohighlight">\(b\)</span> can be generated by this grammar,
and that these are the only strings that can be generated.
That is, the language generated by this grammar is the regular
language specified by the regular expression <span class="math notranslate nohighlight">\((a | b)^{*}b\)</span>.</p>
<p>It’s time to give some formal definitions of the concepts which
we have been discussing.</p>
<blockquote>
<div><p>A <strong>context-free grammar</strong> is a 4-tuple <span class="math notranslate nohighlight">\((V,\Sigma,P,S)\)</span>,
where:</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(V\)</span> is a finite set of symbols. The elements of <span class="math notranslate nohighlight">\(V\)</span>
are the non-terminal symbols of the grammar.</p></li>
<li><p><span class="math notranslate nohighlight">\(\Sigma\)</span> is a finite set of symbols such that <span class="math notranslate nohighlight">\(V\cap\Sigma=\emptyset\)</span>.
The elements of <span class="math notranslate nohighlight">\(\Sigma\)</span> are the terminal symbols of the grammar.</p></li>
<li><p><span class="math notranslate nohighlight">\(P\)</span> is a set of production rules. Each rule is of the
form <span class="math notranslate nohighlight">\(A\longrightarrow w\)</span> where <span class="math notranslate nohighlight">\(A\)</span> is one of the symbols in <span class="math notranslate nohighlight">\(V\)</span> and
<span class="math notranslate nohighlight">\(w\)</span> is a string in the language <span class="math notranslate nohighlight">\((V\cup\Sigma)^*\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(S\in V\)</span>. <span class="math notranslate nohighlight">\(S\)</span> is the start symbol of the grammar.</p></li>
</ol>
</div></blockquote>
<p>Even though this is the formal definition, grammars are often
specified informally simply by listing the set of production rules.
When this is done it is assumed, unless otherwise specified,
that the non-terminal symbols are just the symbols that occur
on the left-hand sides of production rules of the grammar.
The terminal symbols are all the other symbols that occur on
the right-hand sides of production rules. The start symbol is the
symbol that occurs on the left-hand side of the first production
rule in the list. Thus, the list of production rules
<span class="math notranslate nohighlight">\($ \begin{aligned}
   &amp;T\longrightarrow TT\\
   &amp;T\longrightarrow A\\
   &amp;A\longrightarrow aAa\\
   &amp;A\longrightarrow bB\\
   &amp;B\longrightarrow bB\\
   &amp;B\longrightarrow \varepsilon 
  \end{aligned}
$\)</span>
specifies a grammar <span class="math notranslate nohighlight">\(G=(V,\Sigma,P,T)\)</span> where <span class="math notranslate nohighlight">\(V\)</span> is <span class="math notranslate nohighlight">\(\{T,A,B\}\)</span>,
<span class="math notranslate nohighlight">\(\Sigma\)</span> is <span class="math notranslate nohighlight">\(\{a,b\}\)</span>, and <span class="math notranslate nohighlight">\(T\)</span> is the start symbol. <span class="math notranslate nohighlight">\(P\)</span>, of course, is a
set containing the six production rules in the list.</p>
<p>Let <span class="math notranslate nohighlight">\(G=(V,\Sigma,P,S)\)</span> be a context-free grammar.
Suppose that <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> are strings in the language <span class="math notranslate nohighlight">\((V\cup\Sigma)^*\)</span>.
The notation <span class="math notranslate nohighlight">\(x\Longrightarrow_G y\)</span> is used to express the fact
that <span class="math notranslate nohighlight">\(y\)</span> can be obtained from <span class="math notranslate nohighlight">\(x\)</span> by applying one of the production
rules in <span class="math notranslate nohighlight">\(P\)</span>. To be more exact, we say that <span class="math notranslate nohighlight">\(x\Longrightarrow_G y\)</span>
if and only if there is a production rule <span class="math notranslate nohighlight">\(A\longrightarrow w\)</span> in the grammar
and two strings <span class="math notranslate nohighlight">\(u\)</span> and <span class="math notranslate nohighlight">\(v\)</span> in the language <span class="math notranslate nohighlight">\((V\cup\Sigma)^*\)</span>
such that <span class="math notranslate nohighlight">\(x=uAv\)</span> and <span class="math notranslate nohighlight">\(y=uwv\)</span>. The fact
that <span class="math notranslate nohighlight">\(x=uAv\)</span> is just a way of saying that <span class="math notranslate nohighlight">\(A\)</span> occurs somewhere in
<span class="math notranslate nohighlight">\(x\)</span>. When the production rule <span class="math notranslate nohighlight">\(A\longrightarrow w\)</span> is applied to
substitute <span class="math notranslate nohighlight">\(w\)</span> for <span class="math notranslate nohighlight">\(A\)</span> in <span class="math notranslate nohighlight">\(uAv\)</span>, the result is <span class="math notranslate nohighlight">\(uwv\)</span>, which is <span class="math notranslate nohighlight">\(y\)</span>.
Note that either <span class="math notranslate nohighlight">\(u\)</span> or <span class="math notranslate nohighlight">\(v\)</span> or both can be the empty string.</p>
<p>If a string <span class="math notranslate nohighlight">\(y\)</span> can be obtained from a string <span class="math notranslate nohighlight">\(x\)</span> by
applying a sequence of zero or more production rules, we
write <span class="math notranslate nohighlight">\(x\Longrightarrow_G^* y\)</span>. In most cases, the “<span class="math notranslate nohighlight">\(G\)</span>” in
the notations <span class="math notranslate nohighlight">\(\Longrightarrow_G\)</span> and <span class="math notranslate nohighlight">\(\Longrightarrow_G^*\)</span> will be omitted,
assuming that the grammar in question is understood.
Note that <span class="math notranslate nohighlight">\(\Longrightarrow\)</span> is a relation on the set <span class="math notranslate nohighlight">\((V\cup\Sigma)^*\)</span>.
The relation <span class="math notranslate nohighlight">\(\Longrightarrow^*\)</span> is the reflexive, transitive closure of that relation.
(This explains the use of “<span class="math notranslate nohighlight">\(*\)</span>”, which is usually used to
denote the transitive, but not necessarily reflexive, closure of a relation.
In this case, <span class="math notranslate nohighlight">\(\Longrightarrow^*\)</span> is reflexive as well as transitive since
<span class="math notranslate nohighlight">\(x\;\Longrightarrow^* x\)</span> is true for any string <span class="math notranslate nohighlight">\(x\)</span>.)
For example, using the grammar that is defined by the above
list of production rules, we have
<span class="math notranslate nohighlight">\($ \begin{aligned}
 aTB&amp;\Longrightarrow aTTB\\
    &amp;\Longrightarrow aTAB\\
    &amp;\Longrightarrow aTAbB\\
    &amp;\Longrightarrow aTbBbB\\
    &amp;\Longrightarrow aTbbB
  \end{aligned}
$\)</span>
From this, it follows that <span class="math notranslate nohighlight">\(aTB\;\Longrightarrow^* aTbbB\)</span>. The relation <span class="math notranslate nohighlight">\(\Longrightarrow\)</span>
is read “yields” or “produces” while <span class="math notranslate nohighlight">\(\Longrightarrow^*\)</span> can be
read “yields in zero or more steps” or “produces in zero or more
steps.” The following theorem states some simple facts about
the relations <span class="math notranslate nohighlight">\(\Longrightarrow\)</span> and <span class="math notranslate nohighlight">\(\Longrightarrow^*\)</span>:</p>
<blockquote>
<div><p><strong>Theorem:</strong> Let <span class="math notranslate nohighlight">\(G\)</span> be the context-free grammar <span class="math notranslate nohighlight">\((V,\Sigma,P,S)\)</span>.
Then:</p>
<ol class="simple">
<li><p>If <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> are strings in <span class="math notranslate nohighlight">\((V\cup\Sigma)^*\)</span> such that <span class="math notranslate nohighlight">\(x\Longrightarrow y\)</span>,
then <span class="math notranslate nohighlight">\(x\;\Longrightarrow^* y\)</span>.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(x\)</span>, <span class="math notranslate nohighlight">\(y\)</span>, and <span class="math notranslate nohighlight">\(z\)</span> are strings in <span class="math notranslate nohighlight">\((V\cup\Sigma)^*\)</span> such that <span class="math notranslate nohighlight">\(x\;\Longrightarrow^* y\)</span>
and <span class="math notranslate nohighlight">\(y\;\Longrightarrow^* z\)</span>, then <span class="math notranslate nohighlight">\(x\;\Longrightarrow^* z\)</span>.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> are strings in <span class="math notranslate nohighlight">\((V\cup\Sigma)^*\)</span> such that <span class="math notranslate nohighlight">\(x\Longrightarrow y\)</span>,
and if <span class="math notranslate nohighlight">\(s\)</span> and <span class="math notranslate nohighlight">\(t\)</span> are any strings in <span class="math notranslate nohighlight">\((V\cup\Sigma)^*\)</span>, then <span class="math notranslate nohighlight">\(sxt\Longrightarrow syt\)</span>.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> are strings in <span class="math notranslate nohighlight">\((V\cup\Sigma)^*\)</span> such that <span class="math notranslate nohighlight">\(x\;\Longrightarrow^* y\)</span>,
and if <span class="math notranslate nohighlight">\(s\)</span> and <span class="math notranslate nohighlight">\(t\)</span> are any strings in <span class="math notranslate nohighlight">\((V\cup\Sigma)^*\)</span>, then <span class="math notranslate nohighlight">\(sxt\;\Longrightarrow^* syt\)</span>.</p></li>
</ol>
<p><strong>Proof:</strong>
Parts 1 and 2 follow from the fact that <span class="math notranslate nohighlight">\(\Longrightarrow^*\)</span> is the transitive
closure of <span class="math notranslate nohighlight">\(\Longrightarrow\)</span>. Part 4 follows easily from Part 3. (I leave this
as an exercise.) To prove Part 3, suppose that <span class="math notranslate nohighlight">\(x\)</span>, <span class="math notranslate nohighlight">\(y\)</span>, <span class="math notranslate nohighlight">\(s\)</span>, and <span class="math notranslate nohighlight">\(t\)</span>
are strings such that <span class="math notranslate nohighlight">\(x\Longrightarrow y\)</span>. By definition, this means that
there exist strings <span class="math notranslate nohighlight">\(u\)</span> and <span class="math notranslate nohighlight">\(v\)</span> and a production rule <span class="math notranslate nohighlight">\(A\longrightarrow w\)</span>
such that <span class="math notranslate nohighlight">\(x=uAv\)</span> and <span class="math notranslate nohighlight">\(y=uwv\)</span>. But then we also have
<span class="math notranslate nohighlight">\(sxt=suAvt\)</span> and <span class="math notranslate nohighlight">\(syt=suwvt\)</span>. These two equations, along with
the existence of the production rule <span class="math notranslate nohighlight">\(A\longrightarrow w\)</span> show, by definition,
that <span class="math notranslate nohighlight">\(sxt\Longrightarrow syt\)</span>.</p>
</div></blockquote>
<p>We can use <span class="math notranslate nohighlight">\(\Longrightarrow^*\)</span> to give a formal definition
of the language generated by a context-free grammar:</p>
<blockquote>
<div><p>Suppose that <span class="math notranslate nohighlight">\(G=(V,\Sigma,P,S)\)</span> is a context-free grammar.
Then the language generated by <span class="math notranslate nohighlight">\(G\)</span> is the language <span class="math notranslate nohighlight">\(L(G)\)</span> over
the alphabet <span class="math notranslate nohighlight">\(\Sigma\)</span> defined by
<span class="math notranslate nohighlight">\($
L(G)=\{w\in \Sigma^*\;|\; S\Longrightarrow_G^* w\}
$\)</span>
That is, <span class="math notranslate nohighlight">\(L(G)\)</span> contains any string of terminal symbols that can be
obtained by starting with the string consisting of the start symbol, <span class="math notranslate nohighlight">\(S\)</span>,
and applying a sequence of production rules.</p>
<p>A language <span class="math notranslate nohighlight">\(L\)</span> is said to be a <strong>context-free language</strong> if
there is a context-free grammar <span class="math notranslate nohighlight">\(G\)</span> such that <span class="math notranslate nohighlight">\(L(G)\)</span> is <span class="math notranslate nohighlight">\(L\)</span>.
Note that there might be many different context-free grammars
that generate the same context-free language. Two context-free
grammars that generate the same language are said to be
<strong>equivalent</strong>.</p>
</div></blockquote>
<p>Suppose <span class="math notranslate nohighlight">\(G\)</span> is a context-free grammar with start symbol <span class="math notranslate nohighlight">\(S\)</span>
and suppose <span class="math notranslate nohighlight">\(w\in L(G)\)</span>. By definition, this means that
there is a sequence of one or more applications of production rules
which produces the string <span class="math notranslate nohighlight">\(w\)</span> from <span class="math notranslate nohighlight">\(S\)</span>. This sequence has the
form <span class="math notranslate nohighlight">\(S\Longrightarrow x_1\Longrightarrow x_2\Longrightarrow\cdots\Longrightarrow w\)</span>. Such a sequence
is called a <strong>derivation</strong> of <span class="math notranslate nohighlight">\(w\)</span> (in the grammar <span class="math notranslate nohighlight">\(G\)</span>). Note
that <span class="math notranslate nohighlight">\(w\)</span> might have more than one derivation. That is, it might
be possible to produce <span class="math notranslate nohighlight">\(w\)</span> in several different ways.</p>
<p>Consider the language <span class="math notranslate nohighlight">\(L=\{a^nb^n\;|\; n\in\N\}\)</span>. We already know
that <span class="math notranslate nohighlight">\(L\)</span> is not a regular language.[^ TODO] However, it is a context-free
language. That is, there is a context-free grammar such that
<span class="math notranslate nohighlight">\(L\)</span> is the language generated by <span class="math notranslate nohighlight">\(G\)</span>. This gives us our first
theorem about grammars:</p>
<blockquote>
<div><p><strong>Theorem:</strong> Let <span class="math notranslate nohighlight">\(L\)</span> be the language <span class="math notranslate nohighlight">\(L=\{a^nb^n\;|\; n\in\N\}\)</span>. Let <span class="math notranslate nohighlight">\(G\)</span> be
the context-free grammar <span class="math notranslate nohighlight">\((V,\Sigma,P,S)\)</span> where <span class="math notranslate nohighlight">\(V=\{S\}\)</span>,
<span class="math notranslate nohighlight">\(\Sigma=\{a,b\}\)</span> and <span class="math notranslate nohighlight">\(P\)</span> consists of the productions
<span class="math notranslate nohighlight">\($ \begin{aligned}
    &amp;S\longrightarrow aSb\\
    &amp;S\longrightarrow \varepsilon
  \end{aligned}
$\)</span>
Then <span class="math notranslate nohighlight">\(L=L(G)\)</span>, so that <span class="math notranslate nohighlight">\(L\)</span> is a context-free language. In particular,
there exist context-free languages which are not regular.</p>
<p><strong>Proof:</strong>
To show that <span class="math notranslate nohighlight">\(L=L(G)\)</span>, we must show both that <span class="math notranslate nohighlight">\(L\subseteq L(G)\)</span>
and that <span class="math notranslate nohighlight">\(L(G)\subseteq L\)</span>. To show that <span class="math notranslate nohighlight">\(L\subseteq L(G)\)</span>, let <span class="math notranslate nohighlight">\(w\)</span>
be an arbitrary element of <span class="math notranslate nohighlight">\(L\)</span>. By definition of <span class="math notranslate nohighlight">\(L\)</span>,
<span class="math notranslate nohighlight">\(w=a^nb^n\)</span> for some <span class="math notranslate nohighlight">\(n\in\N\)</span>. We show that <span class="math notranslate nohighlight">\(w\in L(G)\)</span> by
induction on <span class="math notranslate nohighlight">\(n\)</span>. In the case where <span class="math notranslate nohighlight">\(n=0\)</span>, we have <span class="math notranslate nohighlight">\(w=\varepsilon\)</span>.
Now, <span class="math notranslate nohighlight">\(\varepsilon\in L(G)\)</span> since <span class="math notranslate nohighlight">\(\varepsilon\)</span> can be produced
from the start symbol <span class="math notranslate nohighlight">\(S\)</span> by an application of the rule <span class="math notranslate nohighlight">\(S\longrightarrow\varepsilon\)</span>,
so our claim is true for <span class="math notranslate nohighlight">\(n=0\)</span>.
Now, suppose that <span class="math notranslate nohighlight">\(k\in\N\)</span> and that we already know that <span class="math notranslate nohighlight">\(a^kb^k\in L(G)\)</span>.
We must show that <span class="math notranslate nohighlight">\(a^{k+1}b^{k+1}\in L(G)\)</span>. Since
<span class="math notranslate nohighlight">\(S\;\Longrightarrow^* a^kb^k\)</span>, we also have, by the previous theorem, that
<span class="math notranslate nohighlight">\(aSb\;\Longrightarrow^* aa^kb^kb\)</span>.
That is, <span class="math notranslate nohighlight">\(aSb\;\Longrightarrow^* a^{k+1}b^{k+1}\)</span>. Combining this with the
production rule <span class="math notranslate nohighlight">\(S\longrightarrow aSb\)</span>, we see that <span class="math notranslate nohighlight">\(S\;\Longrightarrow^* a^{k+1}b^{k+1}\)</span>.
This means that <span class="math notranslate nohighlight">\(a^{k+1}b^{k+1}\in L(G)\)</span>, as we wanted to show.
This completes the proof that <span class="math notranslate nohighlight">\(L\subseteq L(G)\)</span>.</p>
</div></blockquote>
<p>To show that <span class="math notranslate nohighlight">\(L(G)\subseteq L\)</span>, suppose that <span class="math notranslate nohighlight">\(w\in L(G)\)</span>. That is,
<span class="math notranslate nohighlight">\(S\;\Longrightarrow^* w\)</span>. We must show that <span class="math notranslate nohighlight">\(w=a^nb^n\)</span> for some <span class="math notranslate nohighlight">\(n\)</span>.
Since <span class="math notranslate nohighlight">\(S\;\Longrightarrow^* w\)</span>, there is a derivation
<span class="math notranslate nohighlight">\(S\Longrightarrow x_0\Longrightarrow x_1\Longrightarrow\cdots\Longrightarrow x_n\)</span>, where <span class="math notranslate nohighlight">\(w=x_n\)</span>.
We first prove by induction on <span class="math notranslate nohighlight">\(n\)</span> that in any derivation
<span class="math notranslate nohighlight">\(S\Longrightarrow x_0\Longrightarrow x_1\Longrightarrow\cdots\Longrightarrow x_n\)</span>,
we must have either <span class="math notranslate nohighlight">\(x_n=a^nb^n\)</span> or <span class="math notranslate nohighlight">\(x_n=a^{n+1}Sb^{n+1}\)</span>.
Consider the case <span class="math notranslate nohighlight">\(n=0\)</span>. Suppose <span class="math notranslate nohighlight">\(S\Longrightarrow x_0\)</span>.
Then, we must have that <span class="math notranslate nohighlight">\(S\longrightarrow x_0\)</span> is a rule in the grammar,
so <span class="math notranslate nohighlight">\(x_0\)</span> must be either <span class="math notranslate nohighlight">\(\varepsilon\)</span> or <span class="math notranslate nohighlight">\(aSb\)</span>. Since <span class="math notranslate nohighlight">\(\varepsilon=a^0b^0\)</span>
and <span class="math notranslate nohighlight">\(aSb=a^{0+1}Sb^{0+1}\)</span>, <span class="math notranslate nohighlight">\(x_0\)</span> is of the required form.
Next, consider the inductive case. Suppose that <span class="math notranslate nohighlight">\(k&gt;1\)</span> and we already
know that in any
derivation <span class="math notranslate nohighlight">\(S\Longrightarrow x_0\Longrightarrow x_1\Longrightarrow\cdots\Longrightarrow x_k\)</span>,
we must have <span class="math notranslate nohighlight">\(x_k=a^kb^k\)</span> or <span class="math notranslate nohighlight">\(x=a^{k+1}Sb^{k+1}\)</span>. Suppose that
<span class="math notranslate nohighlight">\(S\Longrightarrow x_0\Longrightarrow x_1\Longrightarrow\cdots\Longrightarrow x_k\Longrightarrow x_{k+1}\)</span>.
We know by induction that <span class="math notranslate nohighlight">\(x_k=a^kb^k\)</span> or <span class="math notranslate nohighlight">\(x=a^{k+1}Sb^{k+1}\)</span>,
but since <span class="math notranslate nohighlight">\(x_k\Longrightarrow x_{k+1}\)</span> and <span class="math notranslate nohighlight">\(a^kb^k\)</span> contains no non-terminal
symbols, we must have <span class="math notranslate nohighlight">\(x_k=a^{k+1}Sb^{k+1}\)</span>. Since <span class="math notranslate nohighlight">\(x_{k+1}\)</span>
is obtained by applying one of the production rules <span class="math notranslate nohighlight">\(S\longrightarrow\varepsilon\)</span>
or <span class="math notranslate nohighlight">\(S\longrightarrow aSb\)</span> to <span class="math notranslate nohighlight">\(x_k\)</span>, <span class="math notranslate nohighlight">\(x_{k+1}\)</span> is either <span class="math notranslate nohighlight">\(a^{k+1}\varepsilon b^{k+1}\)</span>
or <span class="math notranslate nohighlight">\(a^{k+1}aSbb^{k+1}\)</span>. That is, <span class="math notranslate nohighlight">\(x_{k+1}\)</span> is either <span class="math notranslate nohighlight">\(a^{k+1}b^{k+1}\)</span>
or <span class="math notranslate nohighlight">\(a^{k+2}Sb^{k+2}\)</span>, as we wanted to show. This completes the induction.
Turning back to <span class="math notranslate nohighlight">\(w\)</span>, we see that <span class="math notranslate nohighlight">\(w\)</span> must be of the form <span class="math notranslate nohighlight">\(a^nb^n\)</span> or
of the form <span class="math notranslate nohighlight">\(a^nSb^n\)</span>. But since <span class="math notranslate nohighlight">\(w\in L(G)\)</span>, it can contain no
non-terminal symbols, so <span class="math notranslate nohighlight">\(w\)</span> must be of the form <span class="math notranslate nohighlight">\(a^nb^n\)</span>, as we wanted to show.
This completes the proof that <span class="math notranslate nohighlight">\(L(G)\subseteq L\)</span>.</p>
<p>I have given a very formal and detailed proof of this theorem, to show how it
can be done and to show how induction plays a role in many proofs about
grammars. However, a more informal proof of the theorem would probably
be acceptable and might even be more convincing. To show that
<span class="math notranslate nohighlight">\(L\subseteq L(G)\)</span>, we could just note that the derivation
<span class="math notranslate nohighlight">\(S\Longrightarrow aSb\Longrightarrow a^2Sb^2\Longrightarrow\cdots\Longrightarrow a^nSb^n\Longrightarrow a^nb^n\)</span>
demonstrates that <span class="math notranslate nohighlight">\(a^nb^n\in L\)</span>. On the other hand, it is clear that every
derivation for this grammar must be of this form, so every string in <span class="math notranslate nohighlight">\(L(G)\)</span>
is of the form <span class="math notranslate nohighlight">\(a^nb^n\)</span>.</p>
<p>For another example, consider the language <span class="math notranslate nohighlight">\(\{a^nb^m\;|\; n\ge m\ge0\}\)</span>.
Let’s try to design a grammar that generates this language.
This is similar to the previous example, but now we want to include strings that
contain more <span class="math notranslate nohighlight">\(a\)</span>’s than <span class="math notranslate nohighlight">\(b\)</span>’s. The production rule <span class="math notranslate nohighlight">\(S\longrightarrow aSb\)</span>
always produces the same number of <span class="math notranslate nohighlight">\(a\)</span>’s and <span class="math notranslate nohighlight">\(b\)</span>’s. Can we modify
this idea to produce more <span class="math notranslate nohighlight">\(a\)</span>’s than <span class="math notranslate nohighlight">\(b\)</span>’s?</p>
<p>One approach would be to produce a string containing just as many
<span class="math notranslate nohighlight">\(a\)</span>’s as <span class="math notranslate nohighlight">\(b\)</span>’s, and then to add some extra <span class="math notranslate nohighlight">\(a\)</span>’s. A rule that can
generate any number of <span class="math notranslate nohighlight">\(a\)</span>’s is <span class="math notranslate nohighlight">\(A\longrightarrow aA\)</span>. After
applying the rule <span class="math notranslate nohighlight">\(S\longrightarrow aSb\)</span> for a while, we want to move
to a new state in which we apply the rule <span class="math notranslate nohighlight">\(A\longrightarrow aA\)</span>. We can
get to the new state by applying a rule <span class="math notranslate nohighlight">\(S\longrightarrow A\)</span>
that changes the <span class="math notranslate nohighlight">\(S\)</span> into an <span class="math notranslate nohighlight">\(A\)</span>. We still need a way to
finish the process, which means getting rid of all non-terminal
symbols in the string. For this, we can use the rule <span class="math notranslate nohighlight">\(A\longrightarrow\varepsilon\)</span>.
Putting these rules together, we get the grammar
<span class="math notranslate nohighlight">\($ \begin{aligned}
      &amp;S\longrightarrow aSb\\
      &amp;S\longrightarrow A\\
      &amp;A\longrightarrow aA\\
      &amp;A\longrightarrow \varepsilon
    \end{aligned}
$\)</span>
This grammar does indeed generate the language <span class="math notranslate nohighlight">\(\{a^nb^m\;|\; n\ge m\ge 0\}\)</span>.
With slight variations on this grammar, we can produce other related
languages. For example, if we replace the rule <span class="math notranslate nohighlight">\(A\longrightarrow \varepsilon\)</span>
with <span class="math notranslate nohighlight">\(A\longrightarrow a\)</span>, we get the language <span class="math notranslate nohighlight">\(\{a^nb^m\;|\; n&gt; m\ge 0\}\)</span>.</p>
<p>There are other ways to generate the language <span class="math notranslate nohighlight">\(\{a^nb^m\;|\; n\ge m\ge 0\}\)</span>.
For example, the extra non-terminal symbol, <span class="math notranslate nohighlight">\(A\)</span>, is not really necessary,
if we allow <span class="math notranslate nohighlight">\(S\)</span> to sometimes produce a single <span class="math notranslate nohighlight">\(a\)</span> without a <span class="math notranslate nohighlight">\(b\)</span>. This
leads to the grammar
<span class="math notranslate nohighlight">\($ \begin{aligned}
      &amp;S\longrightarrow aSb\\
      &amp;S\longrightarrow aS\\
      &amp;S\longrightarrow \varepsilon
    \end{aligned}
$\)</span>
(But note that the rule <span class="math notranslate nohighlight">\(S\longrightarrow Sa\)</span> would not work in place
of <span class="math notranslate nohighlight">\(S\longrightarrow aS\)</span>, since it would allow the production of
strings in which an <span class="math notranslate nohighlight">\(a\)</span> can follow a <span class="math notranslate nohighlight">\(b\)</span>, and there are no
such strings in the language <span class="math notranslate nohighlight">\(\{a^nb^m\;|\; n\ge m\ge 0\}\)</span>.)
And here are two more grammars that generate this language:
<span class="math notranslate nohighlight">\($ \begin{aligned}
      &amp;S\longrightarrow AB\\
      &amp;A\longrightarrow aA\\
      &amp;B\longrightarrow aBb\\
      &amp;A\longrightarrow \varepsilon\\
      &amp;B\longrightarrow \varepsilon
    \end{aligned}
$\)</span>
and
<span class="math notranslate nohighlight">\($ \begin{aligned}
      &amp;S\longrightarrow ASb\\
      &amp;A\longrightarrow aA\\
      &amp;S\longrightarrow\varepsilon\\
      &amp;A\longrightarrow a
    \end{aligned}
$\)</span></p>
<hr class="docutils" />
<p>Consider another variation on the language <span class="math notranslate nohighlight">\(\{a^nb^n\;|\; n\in\N\}\)</span>,
in which the <span class="math notranslate nohighlight">\(a\)</span>’s and <span class="math notranslate nohighlight">\(b\)</span>’s can occur in any order, but the number
of <span class="math notranslate nohighlight">\(a\)</span>’s is still equal to the number of <span class="math notranslate nohighlight">\(b\)</span>’s. This language
can be defined as
<span class="math notranslate nohighlight">\(L=\{w\in\{a,b\}^*\;|\; n_a(w) = n_b(w)\}\)</span>. This language includes
strings such as <span class="math notranslate nohighlight">\(abbaab\)</span>, <span class="math notranslate nohighlight">\(baab\)</span>, and <span class="math notranslate nohighlight">\(bbbaaa\)</span>.</p>
<p>Let’s start with the grammar containing the rules <span class="math notranslate nohighlight">\(S\longrightarrow aSb\)</span>
and <span class="math notranslate nohighlight">\(S\longrightarrow\varepsilon\)</span>. We can try adding the rule
<span class="math notranslate nohighlight">\(S\longrightarrow bSa\)</span>. Every string that can be generated using these
three rules is in the language <span class="math notranslate nohighlight">\(L\)</span>. However, not every string
in <span class="math notranslate nohighlight">\(L\)</span> can be generated. A derivation that starts with <span class="math notranslate nohighlight">\(S\Longrightarrow aSb\)</span>
can only produce strings that begin with <span class="math notranslate nohighlight">\(a\)</span> and end with <span class="math notranslate nohighlight">\(b\)</span>.
A derivation that starts with <span class="math notranslate nohighlight">\(S\Longrightarrow bSa\)</span> can only generate strings
that begin with <span class="math notranslate nohighlight">\(b\)</span> and end with <span class="math notranslate nohighlight">\(a\)</span>. There is no way to generate
the strings <span class="math notranslate nohighlight">\(baab\)</span> or <span class="math notranslate nohighlight">\(abbbabaaba\)</span>, which are in the language <span class="math notranslate nohighlight">\(L\)</span>.
But we shall see that any string in <span class="math notranslate nohighlight">\(L\)</span> that begins and
ends with the same letter can be written in the form <span class="math notranslate nohighlight">\(xy\)</span> where
<span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> are shorter strings in <span class="math notranslate nohighlight">\(L\)</span>. To produce strings of
this form, we need one more rule, <span class="math notranslate nohighlight">\(S\longrightarrow SS\)</span>. The complete set of
production rules for the language <span class="math notranslate nohighlight">\(L\)</span> is
<span class="math notranslate nohighlight">\($ \begin{aligned}
    &amp;S\longrightarrow aSb\\
    &amp;S\longrightarrow bSa\\
    &amp;S\longrightarrow SS\\
    &amp;S\longrightarrow \varepsilon
  \end{aligned}
$\)</span>
It’s easy to see that every string that can be generated using these
rules is in <span class="math notranslate nohighlight">\(L\)</span>, since each rule introduces the same number of
<span class="math notranslate nohighlight">\(a\)</span>’s as <span class="math notranslate nohighlight">\(b\)</span>’s. But we also need to check that every string
<span class="math notranslate nohighlight">\(w\)</span> in <span class="math notranslate nohighlight">\(L\)</span> can be generated by these rules. This can be done
by induction on the length of <span class="math notranslate nohighlight">\(w\)</span>, using the second form
of the principle of mathematical induction. In the base case,
<span class="math notranslate nohighlight">\(|w|=0\)</span> and <span class="math notranslate nohighlight">\(w=\varepsilon\)</span>. In this case, <span class="math notranslate nohighlight">\(w\in L\)</span> since
<span class="math notranslate nohighlight">\(S\Longrightarrow\varepsilon\)</span> in one step.
Suppose <span class="math notranslate nohighlight">\(|w|=k\)</span>, where <span class="math notranslate nohighlight">\(k&gt;0\)</span>, and suppose that
we already know that for any <span class="math notranslate nohighlight">\(x\in L\)</span> with <span class="math notranslate nohighlight">\(|x|&lt;k\)</span>, <span class="math notranslate nohighlight">\(S\;\Longrightarrow^* x\)</span>.
To finish the induction we must show, based on this induction
hypothesis, that <span class="math notranslate nohighlight">\(S\;\Longrightarrow^* w\)</span>.</p>
<p>Suppose that the first and last characters of <span class="math notranslate nohighlight">\(w\)</span> are
different. Then <span class="math notranslate nohighlight">\(w\)</span> is either of the form <span class="math notranslate nohighlight">\(axb\)</span> or of the form <span class="math notranslate nohighlight">\(bxa\)</span>,
for some string <span class="math notranslate nohighlight">\(x\)</span>. Let’s assume that <span class="math notranslate nohighlight">\(w\)</span> is of the form <span class="math notranslate nohighlight">\(axb\)</span>.
(The case where <span class="math notranslate nohighlight">\(w\)</span> is of the form <span class="math notranslate nohighlight">\(bxa\)</span> is handled in a similar way.)
Since <span class="math notranslate nohighlight">\(w\)</span> has the same number of <span class="math notranslate nohighlight">\(a\)</span>’s and <span class="math notranslate nohighlight">\(b\)</span>’s
and since <span class="math notranslate nohighlight">\(x\)</span> has one fewer <span class="math notranslate nohighlight">\(a\)</span> than <span class="math notranslate nohighlight">\(w\)</span> and one fewer <span class="math notranslate nohighlight">\(b\)</span> than <span class="math notranslate nohighlight">\(w\)</span>,
<span class="math notranslate nohighlight">\(x\)</span> must also have the same number of <span class="math notranslate nohighlight">\(a\)</span>’s as <span class="math notranslate nohighlight">\(b\)</span>’s. That is, <span class="math notranslate nohighlight">\(x\in L\)</span>.
But <span class="math notranslate nohighlight">\(|x|=|w|-2&lt;k\)</span>, so by the induction hypothesis, <span class="math notranslate nohighlight">\(x\in L(G)\)</span>.
So we have <span class="math notranslate nohighlight">\(S\;\Longrightarrow^* x\)</span>. By the theorem above, we
get then <span class="math notranslate nohighlight">\(aSb\;\Longrightarrow^* axb\)</span>. Combining this with the fact
that <span class="math notranslate nohighlight">\(S\Longrightarrow aSb\)</span>, we get that <span class="math notranslate nohighlight">\(S\;\Longrightarrow^* axb\)</span>, that is,
<span class="math notranslate nohighlight">\(S\;\Longrightarrow^* w\)</span>. This proves that <span class="math notranslate nohighlight">\(w\in L(G)\)</span>.</p>
<p>Finally, suppose that the first and last characters of <span class="math notranslate nohighlight">\(w\)</span> are
the same. Let’s say that <span class="math notranslate nohighlight">\(w\)</span> begins and ends with <span class="math notranslate nohighlight">\(a\)</span>. (The case
where <span class="math notranslate nohighlight">\(w\)</span> begins and ends with <span class="math notranslate nohighlight">\(b\)</span> is handled in a similar way.)
I claim that <span class="math notranslate nohighlight">\(w\)</span> can be written in the form <span class="math notranslate nohighlight">\(xy\)</span> where <span class="math notranslate nohighlight">\(x\in L(G)\)</span>
and <span class="math notranslate nohighlight">\(y\in L(G)\)</span> and neither <span class="math notranslate nohighlight">\(x\)</span> nor <span class="math notranslate nohighlight">\(y\)</span> is the empty string.
This will finish the induction, since we will then have by
the induction hypothesis that <span class="math notranslate nohighlight">\(S\;\Longrightarrow^* x\)</span>
and <span class="math notranslate nohighlight">\(S\;\Longrightarrow^* y\)</span>, and we can derive <span class="math notranslate nohighlight">\(xy\)</span> from <span class="math notranslate nohighlight">\(S\)</span> by first
applying the rule <span class="math notranslate nohighlight">\(S\longrightarrow SS\)</span> and then using the first
<span class="math notranslate nohighlight">\(S\)</span> on the right-hand side to derive <span class="math notranslate nohighlight">\(x\)</span> and the second to derive <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p>It only remains to figure out how to divide <span class="math notranslate nohighlight">\(w\)</span> into two strings
<span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> which are both in <span class="math notranslate nohighlight">\(L(G)\)</span>. The technique that is used
is one that is more generally useful. Suppose that <span class="math notranslate nohighlight">\(w=c_1c_2\cdots c_k\)</span>,
where each <span class="math notranslate nohighlight">\(c_i\)</span> is either <span class="math notranslate nohighlight">\(a\)</span> or <span class="math notranslate nohighlight">\(b\)</span>. Consider the sequence of
integers <span class="math notranslate nohighlight">\(r_1\)</span>, <span class="math notranslate nohighlight">\(r_2\)</span>, \dots, <span class="math notranslate nohighlight">\(r_k\)</span> where for each <span class="math notranslate nohighlight">\(i = 1, 2, \dots, k\)</span>,
<span class="math notranslate nohighlight">\(r_i\)</span> is the number of <span class="math notranslate nohighlight">\(a\)</span>’s in <span class="math notranslate nohighlight">\(c_1c_2\cdots c_i\)</span> minus the
number of <span class="math notranslate nohighlight">\(b\)</span>’s in <span class="math notranslate nohighlight">\(c_1c_2\cdots c_i\)</span>. Since <span class="math notranslate nohighlight">\(c_1=a\)</span>, <span class="math notranslate nohighlight">\(r_1=1\)</span>.
Since <span class="math notranslate nohighlight">\(w\in L\)</span>, <span class="math notranslate nohighlight">\(r_k=0\)</span>. And since <span class="math notranslate nohighlight">\(c_k=a\)</span>, we must have <span class="math notranslate nohighlight">\(r_{k-1}=
r_k-1 = -1\)</span>. Furthermore the difference between <span class="math notranslate nohighlight">\(r_{i+1}\)</span>
and <span class="math notranslate nohighlight">\(r_i\)</span> is either <span class="math notranslate nohighlight">\(1\)</span> or <span class="math notranslate nohighlight">\(-1\)</span>, for <span class="math notranslate nohighlight">\(i=1,2,\dots,k-1\)</span>.</p>
<p>Since <span class="math notranslate nohighlight">\(r_1=1\)</span> and <span class="math notranslate nohighlight">\(r_{k-1}=-1\)</span> and the value of <span class="math notranslate nohighlight">\(r_i\)</span> goes up or down
by 1 when <span class="math notranslate nohighlight">\(i\)</span> increases by 1, <span class="math notranslate nohighlight">\(r_i\)</span> must be zero for some <span class="math notranslate nohighlight">\(i\)</span>
between 1 and <span class="math notranslate nohighlight">\(k-1\)</span>. That is, <span class="math notranslate nohighlight">\(r_i\)</span> cannot get from 1 to <span class="math notranslate nohighlight">\(-1\)</span> unless
it passes through zero. Let <span class="math notranslate nohighlight">\(i\)</span> be a number between 1 and <span class="math notranslate nohighlight">\(k-1\)</span> such
that <span class="math notranslate nohighlight">\(r_i=0\)</span>. Let <span class="math notranslate nohighlight">\(x=c_1c_2\cdots c_i\)</span> and let <span class="math notranslate nohighlight">\(y=c_{i+1}c_{i+2}\cdots c_k\)</span>.
Note that <span class="math notranslate nohighlight">\(xy=w\)</span>. The fact that <span class="math notranslate nohighlight">\(r_i=0\)</span> means that
the string <span class="math notranslate nohighlight">\(c_1c_2\cdots c_i\)</span> has the same number of <span class="math notranslate nohighlight">\(a\)</span>’s and
<span class="math notranslate nohighlight">\(b\)</span>’s, so <span class="math notranslate nohighlight">\(x\in L(G)\)</span>. It follows automatically that <span class="math notranslate nohighlight">\(y\in L(G)\)</span>
also. Since <span class="math notranslate nohighlight">\(i\)</span> is strictly between 1 and <span class="math notranslate nohighlight">\(k-1\)</span>, neither <span class="math notranslate nohighlight">\(x\)</span> nor
<span class="math notranslate nohighlight">\(y\)</span> is the empty string. This is all that we needed to show
to finish the proof that <span class="math notranslate nohighlight">\(L=L(G)\)</span>.</p>
<p>The basic idea of this proof is that if <span class="math notranslate nohighlight">\(w\)</span> contains the same
number of <span class="math notranslate nohighlight">\(a\)</span>’s as <span class="math notranslate nohighlight">\(b\)</span>’s, then an <span class="math notranslate nohighlight">\(a\)</span> at the beginning
of <span class="math notranslate nohighlight">\(w\)</span> must have a “matching” <span class="math notranslate nohighlight">\(b\)</span> somewhere in <span class="math notranslate nohighlight">\(w\)</span>. This
<span class="math notranslate nohighlight">\(b\)</span> matches the <span class="math notranslate nohighlight">\(a\)</span> in the sense that the corresponding <span class="math notranslate nohighlight">\(r_i\)</span> is
zero, and the <span class="math notranslate nohighlight">\(b\)</span> marks the end of a string <span class="math notranslate nohighlight">\(x\)</span> which contains
the same number of <span class="math notranslate nohighlight">\(a\)</span>’s as <span class="math notranslate nohighlight">\(b\)</span>’s. For example, in the
string <span class="math notranslate nohighlight">\(aababbabba\)</span>, the <span class="math notranslate nohighlight">\(a\)</span> at the beginning of the string
is matched by the third <span class="math notranslate nohighlight">\(b\)</span>, since <span class="math notranslate nohighlight">\(aababb\)</span> is the shortest
prefix of <span class="math notranslate nohighlight">\(aababbabba\)</span> that has an equal number of <span class="math notranslate nohighlight">\(a\)</span>’s
and <span class="math notranslate nohighlight">\(b\)</span>’s.</p>
<p>Closely related to this idea of matching <span class="math notranslate nohighlight">\(a\)</span>’s and <span class="math notranslate nohighlight">\(b\)</span>’s is
the idea of <strong>balanced parentheses</strong>. Consider a string
made up of parentheses, such as <code class="docutils literal notranslate"><span class="pre">(()(()))(())</span></code>.
The parentheses in this sample string are balanced because
each left parenthesis has a matching right parenthesis,
and the matching pairs are properly nested. A careful definition
uses the sort of integer sequence introduced in the above
proof. Let <span class="math notranslate nohighlight">\(w\)</span> be a string of parentheses. Write
<span class="math notranslate nohighlight">\(w=c_1c_2\cdots c_n\)</span>, where each <span class="math notranslate nohighlight">\(c_i\)</span> is either <code class="docutils literal notranslate"><span class="pre">(</span></code>
or <code class="docutils literal notranslate"><span class="pre">)</span></code>. Define a sequence of integers <span class="math notranslate nohighlight">\(r_1\)</span>, <span class="math notranslate nohighlight">\(r_2\)</span>, \dots, <span class="math notranslate nohighlight">\(r_n\)</span>,
where <span class="math notranslate nohighlight">\(r_i\)</span> is the number of left parentheses in <span class="math notranslate nohighlight">\(c_1c_2\cdots c_i\)</span>
minus the number of right parentheses. We say that the parentheses
in <span class="math notranslate nohighlight">\(w\)</span> are balanced if <span class="math notranslate nohighlight">\(r_n=0\)</span> and <span class="math notranslate nohighlight">\(r_i\ge0\)</span> for all <span class="math notranslate nohighlight">\(i=1,2,\dots,n\)</span>.
The fact that <span class="math notranslate nohighlight">\(r_n=0\)</span> says that <span class="math notranslate nohighlight">\(w\)</span> contains the same number of
left parentheses as right parentheses. The fact the <span class="math notranslate nohighlight">\(r_i\ge0\)</span>
means that the nesting of pairs of parentheses is correct:
You can’t have a right parenthesis unless it is balanced by a left
parenthesis in the preceding part of the string. The language
that consists of all balanced strings of parentheses is context-free.
It is generated by the grammar
<span class="math notranslate nohighlight">\($ \begin{aligned}
   &amp;S\longrightarrow (\,S\,)\\
   &amp;S\longrightarrow SS\\
   &amp;S\longrightarrow \varepsilon
  \end{aligned}
$\)</span>
The proof is similar to the preceding proof about strings of
<span class="math notranslate nohighlight">\(a\)</span>’s and <span class="math notranslate nohighlight">\(b\)</span>’s. (It might seem that I’ve made an awfully big
fuss about matching and balancing. The reason is that this
is one of the few things that we can do with context-free languages
that we can’t do with regular languages.)</p>
<hr class="docutils" />
<p>Before leaving this section, we should look at a few more
general results. Since we know that most operations on regular
languages produce languages that are also regular, we can
ask whether a similar result holds for context-free languages.
We will see later that the intersection of two context-free
languages is not necessarily context-free. Also, the
complement of a context-free language is not necessarily
context-free. However, some other operations on context-free
languages do produce context-free languages.</p>
<blockquote>
<div><p><strong>Theorem:</strong>
Suppose that <span class="math notranslate nohighlight">\(L\)</span> and <span class="math notranslate nohighlight">\(M\)</span> are context-free languages.
Then the languages <span class="math notranslate nohighlight">\(L\cup M\)</span>, <span class="math notranslate nohighlight">\(LM\)</span>, and <span class="math notranslate nohighlight">\(L^*\)</span> are also
context-free.</p>
<p><strong>Proof:</strong>
I will prove only the first claim of the theorem, that <span class="math notranslate nohighlight">\(L\cup M\)</span> is
context-free. In the exercises for this section, you are
asked to construct grammars for <span class="math notranslate nohighlight">\(LM\)</span> and <span class="math notranslate nohighlight">\(L^*\)</span> (without giving
formal proofs that your answers are correct).</p>
</div></blockquote>
<p>Let <span class="math notranslate nohighlight">\(G=(V,\Sigma,P,S)\)</span> and <span class="math notranslate nohighlight">\(H=(W,\Gamma,Q,T)\)</span> be context-free grammars
such that <span class="math notranslate nohighlight">\(L=L(G)\)</span> and <span class="math notranslate nohighlight">\(M=L(H)\)</span>. We can assume that <span class="math notranslate nohighlight">\(W\cap V=\emptyset\)</span>,
since otherwise we could simply rename the non-terminal symbols in <span class="math notranslate nohighlight">\(W\)</span>.
The idea of the proof is that to generate a string in <span class="math notranslate nohighlight">\(L\cup M\)</span>,
we first decide whether we want a string in <span class="math notranslate nohighlight">\(L\)</span> or a string in <span class="math notranslate nohighlight">\(M\)</span>.
Once that decision is made, to make a string in <span class="math notranslate nohighlight">\(L\)</span>, we use production
rules from <span class="math notranslate nohighlight">\(G\)</span>, while to make a string in <span class="math notranslate nohighlight">\(M\)</span>, we use rules from <span class="math notranslate nohighlight">\(H\)</span>.
We have to design a grammar, <span class="math notranslate nohighlight">\(K\)</span>, to represent this process.</p>
<p>Let <span class="math notranslate nohighlight">\(R\)</span> be a symbol that is not in any of the alphabets <span class="math notranslate nohighlight">\(V\)</span>, <span class="math notranslate nohighlight">\(W\)</span>, <span class="math notranslate nohighlight">\(\Sigma\)</span>,
or <span class="math notranslate nohighlight">\(\Gamma\)</span>. <span class="math notranslate nohighlight">\(R\)</span> will be the start symbol of <span class="math notranslate nohighlight">\(K\)</span>. The production rules
for <span class="math notranslate nohighlight">\(K\)</span> consist of all the production rules from <span class="math notranslate nohighlight">\(G\)</span> and <span class="math notranslate nohighlight">\(H\)</span> together
with two new rules:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\begin{split} \begin{aligned}
&gt;   &amp;R\longrightarrow S\\
&gt;   &amp;R\longrightarrow T
&gt;   \end{aligned}
&gt; \end{split}\]</div>
<p>Formally, <span class="math notranslate nohighlight">\(K\)</span> is defined to be the grammar
<span class="math notranslate nohighlight">\($
 (V\cup W\cup\{R\},
      P\cup Q\cup \{R\longrightarrow S, R\longrightarrow T\},
      \Sigma\cup\Gamma, R)
$\)</span>
Suppose that <span class="math notranslate nohighlight">\(w\in L\)</span>. That is <span class="math notranslate nohighlight">\(w\in L(G)\)</span>, so there is
a derivation <span class="math notranslate nohighlight">\(S\Longrightarrow_G^*w\)</span>.
Since every rule from <span class="math notranslate nohighlight">\(G\)</span> is also a rule in <span class="math notranslate nohighlight">\(K\)</span>, if follows that
<span class="math notranslate nohighlight">\(S\Longrightarrow_K^* w\)</span>. Combining this with the fact that <span class="math notranslate nohighlight">\(R\Longrightarrow_K S\)</span>, we have
that <span class="math notranslate nohighlight">\(R\Longrightarrow_K^* w\)</span>, and <span class="math notranslate nohighlight">\(w\in L(K)\)</span>. This shows that <span class="math notranslate nohighlight">\(L\subseteq L(K)\)</span>.
In an exactly similar way, we can show that <span class="math notranslate nohighlight">\(M\subseteq L(K)\)</span>.
Thus, <span class="math notranslate nohighlight">\(L\cup M\subseteq L(K)\)</span>.</p>
</div></blockquote>
<p>It remains to show that <span class="math notranslate nohighlight">\(L(K)\subseteq L\cup M\)</span>. Suppose <span class="math notranslate nohighlight">\(w\in L(K)\)</span>.
Then there is a derivation <span class="math notranslate nohighlight">\(R\Longrightarrow_K^*w\)</span>. This derivation must
begin with an application of
one of the rules <span class="math notranslate nohighlight">\(R\longrightarrow S\)</span> or <span class="math notranslate nohighlight">\(R\longrightarrow T\)</span>, since these are the
only rules in which <span class="math notranslate nohighlight">\(R\)</span> appears. If the first rule applied in the
derivation is <span class="math notranslate nohighlight">\(R\longrightarrow S\)</span>, then the remainder of the derivation
shows that <span class="math notranslate nohighlight">\(S\Longrightarrow_K^*w\)</span>. Starting from <span class="math notranslate nohighlight">\(S\)</span>, the only rules
that can be applied are rules from <span class="math notranslate nohighlight">\(G\)</span>, so in fact we have
<span class="math notranslate nohighlight">\(S\Longrightarrow_G^*w\)</span>. This shows that <span class="math notranslate nohighlight">\(w\in L\)</span>. Similarly, if
the first rule applied in the derivation <span class="math notranslate nohighlight">\(R\Longrightarrow_K^*w\)</span> is
<span class="math notranslate nohighlight">\(R\longrightarrow T\)</span>, then <span class="math notranslate nohighlight">\(w\in M\)</span>. In any case, <span class="math notranslate nohighlight">\(w\in L\cup M\)</span>.
This proves that <span class="math notranslate nohighlight">\(L(K)\subseteq L\cup M\)</span>.</p>
<p>Finally, we should clarify the relationship between context-free
languages and regular languages. We have already seen that
there are context-free languages which are not regular.
On the other hand, it turns out that every regular language
is context-free. That is, given any regular language, there
is a context-free grammar that generates that language. This
means that any syntax that can be expressed by a regular expression,
by a DFA, or by an NFA could also be expressed by a context-free
grammar. In fact, we only need a certain restricted type of
context-free grammar to duplicate the power of regular expressions.</p>
<blockquote>
<div><p>A <strong>right-regular grammar</strong> is a context-free
grammar in which the right-hand side of every production
rule has one of the following forms: the empty string;
a string consisting of a single non-terminal symbol; or
a string consisting of a single terminal symbol followed
by a single non-terminal symbol.</p>
</div></blockquote>
<p>Examples of the types of production rule that are allowed in
a right-regular grammar are <span class="math notranslate nohighlight">\(A\longrightarrow\varepsilon\)</span>,
<span class="math notranslate nohighlight">\(B\longrightarrow C\)</span>, and <span class="math notranslate nohighlight">\(D\longrightarrow aE\)</span>. The idea of the
proof is that given a right-regular grammar, we can build
a corresponding <span class="math notranslate nohighlight">\(NFA\)</span> and <em>vice-versa</em>. The
states of the <span class="math notranslate nohighlight">\(NFA\)</span> correspond to the non-terminal symbols
of the grammar. The start symbol of the grammar corresponds
to the starting state of the NFA.
A production rule of the form <span class="math notranslate nohighlight">\(A\longrightarrow bC\)</span>
corresponds to a transition in the NFA from state <span class="math notranslate nohighlight">\(A\)</span> to state
<span class="math notranslate nohighlight">\(C\)</span> while reading the symbol <span class="math notranslate nohighlight">\(b\)</span>. A production rule of
the form <span class="math notranslate nohighlight">\(A\longrightarrow B\)</span> corresponds to an <span class="math notranslate nohighlight">\(\varepsilon\)</span>-transition
from state <span class="math notranslate nohighlight">\(A\)</span> to state <span class="math notranslate nohighlight">\(B\)</span> in the NFA. And a production
rule of the form <span class="math notranslate nohighlight">\(A\longrightarrow\varepsilon\)</span> exists in the grammar
if and only if <span class="math notranslate nohighlight">\(A\)</span> is a final state in the NFA. With this
correspondence, a derivation of a string <span class="math notranslate nohighlight">\(w\)</span> in the grammar
corresponds to an execution path through the NFA as it
accepts the string <span class="math notranslate nohighlight">\(w\)</span>. I won’t give a complete proof
here. You are welcome to work through the details if you want.
But the important fact is:</p>
<blockquote>
<div><p><strong>Theorem:</strong>
A language <span class="math notranslate nohighlight">\(L\)</span> is regular if and only if there is a right-regular
grammar <span class="math notranslate nohighlight">\(G\)</span> such that <span class="math notranslate nohighlight">\(L=L(G)\)</span>. In particular, every regular
language is context-free.</p>
</div></blockquote>
<div class="section" id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<ol>
<li><p>Show that Part 4 of the theorem about <span class="math notranslate nohighlight">\(\Longrightarrow^*\)</span> follows from Part 3.</p></li>
<li><p>Give a careful proof that the language <span class="math notranslate nohighlight">\(\{a^nb^m\;|\; n\ge m\ge 0\}\)</span>
is generated by the context-free grammar
<span class="math notranslate nohighlight">\($ \begin{aligned}
   &amp;S\longrightarrow aSb\\
   &amp;S\longrightarrow A\\
   &amp;A\longrightarrow aA\\
   &amp;A\longrightarrow \varepsilon
 \end{aligned}
$\)</span></p></li>
<li><p>Identify the language generated by each of the following
context-free grammars.</p>
<ul>
<li><div class="math notranslate nohighlight">
\[\begin{split} \begin{aligned}
      &amp;S\longrightarrow aaSb\\
      &amp;S\longrightarrow \varepsilon
      \end{aligned}
     \end{split}\]</div>
</li>
<li><div class="math notranslate nohighlight">
\[\begin{split} \begin{aligned}
      &amp;S\longrightarrow aSb\\
      &amp;S\longrightarrow aaSb\\
      &amp;S\longrightarrow \varepsilon
      \end{aligned}
     \end{split}\]</div>
</li>
<li><div class="math notranslate nohighlight">
\[\begin{split} \begin{aligned}
      &amp;S\longrightarrow TS\\
      &amp;S\longrightarrow \varepsilon\\
      &amp;T\longrightarrow aTb\\
      &amp;T\longrightarrow \varepsilon
      \end{aligned}
     \end{split}\]</div>
</li>
<li><div class="math notranslate nohighlight">
\[\begin{split} \begin{aligned}
      &amp;S\longrightarrow ABA\\
      &amp;A\longrightarrow aA\\
      &amp;A\longrightarrow a\\
      &amp;B\longrightarrow bB\\
      &amp;B\longrightarrow cB\\
      &amp;B\longrightarrow\varepsilon
      \end{aligned}
     \end{split}\]</div>
</li>
</ul>
</li>
<li><p>For each of the following languages
find a context-free grammar that generates the language:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\{a^nb^m\;|\; n\ge m &gt; 0\}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\{a^nb^m\;|\; n, m\in\N \}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\{a^nb^m\;|\; n\ge0\land m=n+1\}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\{a^nb^mc^n\;|\; n,m\in\N \}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\{ a^nb^mc^k \;|\; n=m+k \}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\{a^nb^m\;|\; n\not=m\}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\{ a^nb^mc^rd^t\;|\; n+m=r+t \}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\{ a^nb^mc^k \;|\; n\not=m+k \}\)</span></p></li>
</ul>
</li>
<li><p>Find a context-free grammar that generates the language
<span class="math notranslate nohighlight">\(\{w\in\{a,b\}^*\;|\; n_a(w) &gt; n_b(w)\}\)</span>.</p></li>
<li><p>Find a context-free grammar that generates the language
<span class="math notranslate nohighlight">\(\{w\in\{a,b,c\}^*\;|\; n_a(w) = n_b(w)\}\)</span>.</p></li>
<li><p>A <strong>palindrome</strong> is a string that reads the same
backwards and forwards, such as “mom”, “radar”, or
“aabccbccbaa”. That is, <span class="math notranslate nohighlight">\(w\)</span> is a palindrome if <span class="math notranslate nohighlight">\(w=w^R\)</span>.
Let <span class="math notranslate nohighlight">\(L=\{w\in\{a,b,c\}^*\;|\; w\textrm{ is a palindrome}\}\)</span>.
Show that <span class="math notranslate nohighlight">\(L\)</span> is a context-free language by finding a context-free
grammar that generates <span class="math notranslate nohighlight">\(L\)</span>.</p></li>
<li><p>Let <span class="math notranslate nohighlight">\(\Sigma=\{\,\texttt{(},\,\texttt{)},\,\texttt{[},\,\texttt{]}\,\}\)</span>. That is, <span class="math notranslate nohighlight">\(\Sigma\)</span>
is the alphabet consisting of the four symbols <span class="math notranslate nohighlight">\(\texttt{(}\)</span>, <span class="math notranslate nohighlight">\(\texttt{)}\)</span>, <span class="math notranslate nohighlight">\(\texttt{[}\)</span>, and <span class="math notranslate nohighlight">\(\texttt{]}\)</span>.
Let <span class="math notranslate nohighlight">\(L\)</span> be the language over <span class="math notranslate nohighlight">\(\Sigma\)</span> consisting of strings
in which both parentheses and brackets are balanced.
For example, the string <span class="math notranslate nohighlight">\(\texttt{([][()()])([])}\)</span> is in <span class="math notranslate nohighlight">\(L\)</span>
but <span class="math notranslate nohighlight">\(\texttt{[(])}\)</span> is not. Find a context-free grammar that generates the
language <span class="math notranslate nohighlight">\(L\)</span>.</p></li>
<li><p>Suppose that <span class="math notranslate nohighlight">\(G\)</span> and <span class="math notranslate nohighlight">\(H\)</span> are context-free grammars.
Let <span class="math notranslate nohighlight">\(L=L(G)\)</span> and let <span class="math notranslate nohighlight">\(M=L(H)\)</span>. Explain how to construct
a context-free grammar for the language <span class="math notranslate nohighlight">\(LM\)</span>. You do not
need to give a formal proof that your grammar is correct.</p></li>
<li><p>Suppose that <span class="math notranslate nohighlight">\(G\)</span> is a context-free grammar.
Let <span class="math notranslate nohighlight">\(L=L(G)\)</span>. Explain how to construct
a context-free grammar for the language <span class="math notranslate nohighlight">\(L^*\)</span>. You do not
need to give a formal proof that your grammar is correct.</p></li>
<li><p>Suppose that <span class="math notranslate nohighlight">\(L\)</span> is a context-free language.
Prove that <span class="math notranslate nohighlight">\(L^R\)</span> is a context-free language. (Hint:
Given a context-free grammar <span class="math notranslate nohighlight">\(G\)</span> for <span class="math notranslate nohighlight">\(L\)</span>, make a new grammar, <span class="math notranslate nohighlight">\(G^R\)</span>,
by reversing the right-hand side of each of the production
rules in <span class="math notranslate nohighlight">\(G\)</span>. That is, <span class="math notranslate nohighlight">\(A\longrightarrow w\)</span> is a production rule in
<span class="math notranslate nohighlight">\(G\)</span> if and only if <span class="math notranslate nohighlight">\(A\longrightarrow w^R\)</span> is a production rule in <span class="math notranslate nohighlight">\(G^R\)</span>.)</p></li>
<li><p>Define a <strong>left-regular grammar</strong>
to be a context-free grammar in which the right-hand side of
every production rule is of one of the following forms:
the empty string; a single non-terminal symbol; or a non-terminal
symbol followed by a terminal symbol. Show that a language is
regular if and only if it can be generated by a left-regular
grammar. (Hint: Use the preceding exercise and the theorem
about right-regular grammars.)</p></li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./lang"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="fsareg.html" title="previous page">Finite-State Automata and Regular Languages</a>
    <a class='right-next' id="next-link" href="bnf.html" title="next page">Backus-Naur Form</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Brian T. Howard, based in part on material by Carol Critchlow and David Eck<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>